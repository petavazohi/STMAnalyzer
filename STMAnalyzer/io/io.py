import h5py
from pathlib import Path
from typing import Tuple, Dict, Any, Union
import numpy as np

def read_hdf5(path: Union[Path, str]) -> Dict[str, Any]:
    """
    Reads an HDF5 file generated by MATLAB and extracts the datasets 
    into a structured dictionary. It handles both nested groups (e.g., 
    /run1/clusterIndex) and top-level datasets (e.g., /weights).

    Args:
        path (Union[Path, str]): The path to the HDF5 file without an 
            explicit extension (either .h5 or .hdf5).

    Returns:
        Dict[str, Any]: A dictionary containing the extracted datasets. 
        Nested groups are represented as nested dictionaries.

    Raises:
        FileNotFoundError: If no valid HDF5 file (.h5 or .hdf5) is found at 
            the provided path.
    
    Notes:
        - If the dataset key is 'clusterIndex', the function adjusts the 
          indexing from MATLAB's 1-based to Python's 0-based indexing by 
          subtracting 1 from the values.
        - For nested groups, each group's datasets are added as dictionaries 
          inside the main dictionary.

    Example:
        Given an HDF5 file with the following structure:
        
            /run1/clusterIndex (N, 1)  # N: Input data size
            /run1/hitHistogram (n*m, 1)  # SOM hit histogram for nxm SOM
            /weights (M, n*m)  # M: Number of features
        
        The output dictionary will look like:

        {
            "run1": {
                "clusterIndex": [...],  # Adjusted for 0-based indexing
                "hitHistogram": [...]
            },
            "weights": [...]
        }
    """
    matlab_output = {}
    path = Path(path)
    
    # Identify the appropriate HDF5 file path
    output_path = next(
        (rf for rf in [path.with_suffix(ext) for ext in ['.h5', '.hdf5']] if rf.exists()),
        None
    )
    
    if not output_path:
        raise FileNotFoundError(f"No HDF5 file found at {path} with .h5 or .hdf5 extensions")
    # Open the HDF5 file and parse datasets into a structured dictionary
    with h5py.File(output_path, 'r') as rf:
        attribs = {
            key:(value[0] if isinstance(value, (list, tuple, np.ndarray)) and len(value) == 1 else value)
                   for key, value in rf.attrs.items()
                   }
        for key in rf.keys():
            if isinstance(rf[key], h5py.Group):
                # Handle nested groups
                matlab_output[key] = {}
                for subkey in rf[key].keys():
                    data = rf[key][subkey][()]
                    # Check if the data is a string dataset
                    if isinstance(data, bytes):
                        data = data.decode('utf-8')
                    else:
                        data = np.squeeze(data)
                        # Adjust for MATLAB 1-based indexing if subkey is 'clusterIndex'
                        if subkey == 'clusterIndex':
                            data = data.astype(int) - 1
                    matlab_output[key][subkey] = data.T
            elif isinstance(rf[key], h5py.Dataset):
                # Handle direct datasets
                data = rf[key][()]
                # Check if the data is a string dataset
                data = np.squeeze(data)
                matlab_output[key] = data
    return matlab_output, attribs
